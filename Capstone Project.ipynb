{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Nov  2 14:02:22 2018\n",
    "\n",
    "@author: Vasudev the Great\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API \n",
    "access_token = \"1045380725632106496-m9ARszPzmQ7RXbmiYVfws8azBOVuWJ\"\n",
    "access_token_secret = \"VozPM5idWCbNQKFLJpch3GgdbZRDRlhihh1dzL72IsNxp\"\n",
    "consumer_key = \"i66bjNNV4Lem9RkEv5R97o5uH\"\n",
    "consumer_secret = \"MfnLzhCw7R5niUmk2hwzt3NB8av6Ac4SFk8b8Of8mGdZ6wCLxl\"\n",
    "\n",
    "# creating an OAuthHandler \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "API = tweepy.API(auth)\n",
    "\n",
    "# creates a dict object for each tweet\n",
    "results = [status._json for status in tweepy.Cursor(API.search, q=\"$EURUSD\",\n",
    "                    count=1200, tweet_mode='extended', lang='en').items()]\n",
    "# creates an empty list\n",
    "# gets the last 3 days as test data and 7 days before that as training data\n",
    "train_tweets = []\n",
    "test_tweets = []\n",
    "past = datetime.utcnow() - timedelta(days = 3)\n",
    "past2 = past - timedelta(days = 7)\n",
    "# populates the list with only tweet text\n",
    "i, j = 0, 0\n",
    "for result in results:\n",
    "    time_created = datetime.strptime(result['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "    time_created = time_created.replace(tzinfo = None)\n",
    "    \n",
    "    if time_created < past and result['retweeted'] is False and time_created > past2:\n",
    "        train_tweets.append({})\n",
    "        train_tweets[i]['created_at'] = time_created\n",
    "        train_tweets[i]['Tweet'] = result['full_text']\n",
    "        i += 1\n",
    "    if time_created > past and result['retweeted'] is False:\n",
    "        test_tweets.append({})\n",
    "        test_tweets[j]['created_at'] = time_created\n",
    "        test_tweets[j]['Tweet'] = result['full_text']\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @JStanleyFX: video of today's webinar posted and ready to go: US Dollar Price Action Setups in EUR/USD, USD/CAD and USD/CHF https://t.co…\n",
      "video of today's webinar posted and ready to go: US Dollar Price Action Setups in EUR/USD, USD/CAD and USD/CHF https://t.co/WvVJZun1AJ $USD $EURUSD $USDCAD $USDCHF https://t.co/bHTgnNv4NJ\n",
      "Haven't posted about Dixie recently, but it's sort of playing out as I expected, though it may be running out of steam, depending on what happens to $EURUSD in the coming week or so. But for now... wheeeee! $USD $DXY #FOREX https://t.co/CLG0uLcNWN\n",
      "$EURUSD Do you know how to Trade \"A Throwover\" ? https://t.co/zuY921ZJhQ\n",
      "RT @commander10: $EURUSD may be forming this inverse H&amp;S on daily chart. Target = 1.1689. #bullish if breaks &amp; holds above. https://t.co/co…\n"
     ]
    }
   ],
   "source": [
    "# print a few raw tweets collected\n",
    "for i in range(0, 5):\n",
    "    print(train_tweets[i]['Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '^b[\\'\"]'\n",
    "regex_url = \"(www|http:|https:|bit)+[^\\s]+[\\w]\"\n",
    "regex_userTags = '@[a-zA-Z:]+'\n",
    "\n",
    "\n",
    "i = 0\n",
    "for dic in train_tweets:\n",
    "    train_tweets[i]['Tweet'] = re.sub(regex, '', dic['Tweet'])\n",
    "    train_tweets[i]['Tweet'] = re.sub(regex_url, '', dic['Tweet'])\n",
    "    train_tweets[i]['Tweet'] = re.sub(regex_userTags, '', dic['Tweet'])\n",
    "    i += 1\n",
    "\n",
    "j = 0\n",
    "for dic in test_tweets:\n",
    "    test_tweets[j]['Tweet'] = re.sub(regex, '', dic['Tweet'])\n",
    "    test_tweets[j]['Tweet'] = re.sub(regex_url, '', dic['Tweet'])\n",
    "    test_tweets[j]['Tweet'] = re.sub(regex_userTags, '', dic['Tweet'])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT  video of today's webinar posted and ready to go: US Dollar Price Action Setups in EUR/USD, USD/CAD and USD/CHF …\n",
      "video of today's webinar posted and ready to go: US Dollar Price Action Setups in EUR/USD, USD/CAD and USD/CHF  $USD $EURUSD $USDCAD $USDCHF \n",
      "Haven't posted about Dixie recently, but it's sort of playing out as I expected, though it may be running out of steam, depending on what happens to $EURUSD in the coming week or so. But for now... wheeeee! $USD $DXY #FOREX \n",
      "$EURUSD Do you know how to Trade \"A Throwover\" ? \n",
      "RT 10: $EURUSD may be forming this inverse H&amp;S on daily chart. Target = 1.1689. #bullish if breaks &amp; holds above. …\n"
     ]
    }
   ],
   "source": [
    "# print a few cleaned tweets\n",
    "for i in range(0,5):\n",
    "    print(train_tweets[i]['Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fxcmpy\n",
    "from datetime import timedelta\n",
    "\n",
    "api = fxcmpy.fxcmpy(config_file='fxcm.cfg')\n",
    "symbol = 'EUR/USD'\n",
    "labels = []\n",
    "#data retrieval\n",
    "for struc in train_tweets:\n",
    "    start = struc['created_at'] - timedelta(minutes = 1)\n",
    "    start = start.replace(second = 0)\n",
    "    stop = struc['created_at'] + timedelta(minutes = 1)\n",
    "    stop = stop.replace(second = 0)\n",
    "    candles = api.get_candles(symbol, period = 'm1', start = start, stop = stop)\n",
    "    try:\n",
    "        labels.append(np.sign( candles['bidclose'].iloc[1] - candles['bidopen'].iloc[0] ))\n",
    "    except:\n",
    "        labels.append(None)\n",
    "        # do nothing\n",
    "\n",
    "test_labels = []\n",
    "for struc in test_tweets:\n",
    "    start = struc['created_at'] - timedelta(minutes = 1)\n",
    "    start = start.replace(second = 0)\n",
    "    stop = struc['created_at'] + timedelta(minutes = 1)\n",
    "    stop = stop.replace(second = 0)\n",
    "    candles = api.get_candles(symbol, period = 'm1', start = start, stop = stop)\n",
    "    try:\n",
    "        test_labels.append(np.sign( candles['bidclose'].iloc[1] - candles['bidopen'].iloc[0] ))\n",
    "    except:\n",
    "        test_labels.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# print a few labels\n",
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of instances for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives: 403\n",
      "Number of negatives: 386\n",
      "Number of neutrals: 27\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "for it in test_labels:\n",
    "    if it == 1:\n",
    "        positive += 1\n",
    "    if it == 0:\n",
    "        neutral += 1\n",
    "    if it == -1:\n",
    "        negative += 1\n",
    "print('Number of positives: ' + str(positive))\n",
    "print('Number of negatives: ' + str(negative))\n",
    "print('Number of neutrals: ' + str(neutral))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Document Term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "train_tweets_text = []\n",
    "test_tweets_text = []\n",
    "labels_shortened = []\n",
    "# remove tweets that don't have a label\n",
    "i = 0\n",
    "for text in train_tweets:\n",
    "    if labels[i] != None:\n",
    "        train_tweets_text.append(text['Tweet'])\n",
    "    i += 1\n",
    "    \n",
    "for j in range(0, len(labels)):\n",
    "    if labels[j] != None:\n",
    "        labels_shortened.append(labels[j])\n",
    "\n",
    "for text in test_tweets:\n",
    "    test_tweets_text.append(text['Tweet'])\n",
    "    \n",
    "# remove stop words by using the nltk stop words set\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('$')\n",
    "stop_words.add('&')\n",
    "stop_words.add('~')\n",
    "stop_words.add('@')\n",
    "stop_words.add('#')\n",
    "stop_words.add('!')\n",
    "stop_words.add(':')\n",
    "stop_words.add(',')\n",
    "stop_words.add('.')\n",
    "stop_words.add('-')\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word', stop_words = stop_words)\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train_tweets_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print train data features\n",
    "train_data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest = RandomForestClassifier(n_estimators = 100)\n",
    "Forest = Forest.fit(train_data_features, labels_shortened)\n",
    "\n",
    "# vectorizing a test dataset\n",
    "test_data_features = vectorizer.transform(test_tweets_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the results, using the model\n",
    "predict = Forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "False_neutral_type1 = 0\n",
    "False_neutral_type2 = 0\n",
    "False_neutral_type3 = 0\n",
    "False_neutral_type4 = 0\n",
    "True_neutral = 0\n",
    "\n",
    "for actual in test_labels:\n",
    "    if actual != None:\n",
    "        if predict[i] == 1 and actual == 1:\n",
    "            TP += 1\n",
    "        if predict[i] == 1 and actual == 0:\n",
    "            False_neutral_type1 += 1\n",
    "        if predict[i] == 0 and actual == 1:\n",
    "            False_neutral_type2 += 1\n",
    "        if predict[i] == 0 and actual == -1:\n",
    "            False_neutral_type3 += 1\n",
    "        if predict[i] == -1 and actual == 0:\n",
    "            False_neutral_type4 += 1\n",
    "        if predict[i] == 0 and actual == 0:\n",
    "            True_neutral += 1\n",
    "        if predict[i] == -1 and actual == 1:\n",
    "            FN += 1\n",
    "        if predict[i] == -1 and actual == -1:\n",
    "            TN += 1\n",
    "        if predict[i] == 1 and actual == -1:\n",
    "            FP += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1     0     -1\n",
      "[181, 11, 169]\n",
      "[2, 0, 3]\n",
      "[220, 16, 214]\n"
     ]
    }
   ],
   "source": [
    "# print Confusion Matrix\n",
    "print('  1','    0','    -1')\n",
    "print([TP, False_neutral_type1, FP])\n",
    "print([False_neutral_type2, True_neutral, False_neutral_type3])\n",
    "print([FN, False_neutral_type4, TN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:\n",
      "0.4840686274509804\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is:')\n",
    "print((TP + True_neutral + TN)/(TP + True_neutral + \n",
    "TN + False_neutral_type1 + FP + False_neutral_type2 + False_neutral_type3 \n",
    "+ FN + False_neutral_type4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:\n",
      "0.5013850415512465\n",
      "Accuracy is:\n",
      "0.22181372549019607\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision is:\")\n",
    "print(181/(181+11+169))\n",
    "print('Accuracy is:')\n",
    "print(181/(TP + True_neutral + \n",
    "TN + False_neutral_type1 + FP + False_neutral_type2 + False_neutral_type3 \n",
    "+ FN + False_neutral_type4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
